{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabs in text: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53514"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the book\n",
    "loader = PyPDFLoader(\"../downloaded-paper.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "for page in pages:\n",
    "    text += page.page_content\n",
    "\n",
    "tabs = text.count('\\t')\n",
    "print(f\"Tabs in text: {tabs}\")\n",
    "text = text.replace('\\t', ' ')\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = ''\n",
    "openai.api_key = openai_api_key\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "947"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.count('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEEING IS BELIEVING : B RAIN -INSPIRED MODULAR\n",
      "TRAINING FOR MECHANISTIC INTERPRETABILITY\n",
      "Ziming Liu, Eric Gan & Max Tegmark\n",
      "Department of Physics, Institute for AI and Fundamental Interactions, MIT\n",
      "{zmliu,ejgan,tegmark}@mit.edu\n",
      "ABSTRACT\n",
      "We introduce Brain-Inspired Modular Training (BIMT), a method for making neural\n",
      "networks more modular and interpretable. Inspired by brains, BIMT embeds neu-\n",
      "rons in a geometric space and augments the loss function with a cost proportional\n",
      "to the length of each neuron connection. We demonstrate that BIMT discovers\n",
      "useful modular neural networks for many simple tasks, revealing compositional\n",
      "structures in symbolic formulas, interpretable decision boundaries and features\n",
      "for classification, and mathematical structure in algorithmic datasets. The ability\n",
      "to directly seemodules with the naked eye can complement current mechanistic\n",
      "interpretability strategies such as probes, interventions or staring at all weights.\n",
      "1 I NTRODUCTION\n",
      "Although deep neural networ\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15022\n"
     ]
    }
   ],
   "source": [
    "num_tokens = llm.get_num_tokens(text)\n",
    "print(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\", \"\\t\"], chunk_size=2000, chunk_overlap=200)\n",
    "\n",
    "docs = text_splitter.create_documents([text])\n",
    "# print(docs[0].page_content)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings: HuggingFaceEmbeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = embeddings.embed_documents([x.page_content for x in docs])\n",
    "vectors=np.array([np.array(v) for v in vectors])\n",
    "print(len(vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 20\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def generate_tsne_graph(vectors):\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    reduced_data_tsne = tsne.fit_transform(vectors)\n",
    "\n",
    "    # Plot the reduced data\n",
    "    plt.scatter(reduced_data_tsne[:, 0], reduced_data_tsne[:, 1], c=kmeans.labels_)\n",
    "    plt.xlabel('Dimension 1')\n",
    "    plt.ylabel('Dimension 2')\n",
    "    plt.title('Book Embeddings Clustered')\n",
    "    plt.show()\n",
    "\n",
    "print(vectors.shape)\n",
    "\n",
    "generate_tsne_graph(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import ARXIV_MD_SUMMARIZATION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.schema import HumanMessage\n",
    "llm3 = ChatOpenAI(temperature=0,\n",
    "                 openai_api_key=openai_api_key,\n",
    "                 max_tokens=1000,\n",
    "                 model='gpt-3.5-turbo'\n",
    "                )\n",
    "\n",
    "llm4 = ChatOpenAI(temperature=0,\n",
    "                 openai_api_key=openai_api_key,\n",
    "                 max_tokens=1000,\n",
    "                 model='gpt-4'\n",
    "                )\n",
    "\n",
    "# map_chain = load_summarize_chain(llm=llm3,\n",
    "#                              chain_type=\"stuff\",\n",
    "#                              prompt=ARXIV_MD_SUMMARIZATION_PROMPT)\n",
    "\n",
    "\n",
    "# map_chain = ConversationChain(llm=llm, verbose=True, prompt=ARXIV_MD_SUMMARIZATION_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling ChatGPT3 with 2019 tokens\n",
      "\n",
      "Please identify and extract all distinct sections from the provided technical paper, including the title, abstract, introduction, \n",
      "methodology, results, discussion, conclusion, and any other relevant parts. Return the extracted sections as a JSON object, with each\n",
      "section as a key-value pair, where the key is the section name and the value is the corresponding text. The text is as shown below \n",
      "surrounded by triple batticks.\n",
      "   \n",
      "    ```SEEING IS BELIEVING : B RAIN -INSPIRED MODULAR\n",
      "TRAINING FOR MECHANISTIC INTERPRETABILITY\n",
      "Ziming Liu, Eric Gan & Max Tegmark\n",
      "Department of Physics, Institute for AI and Fundamental Interactions, MIT\n",
      "{zmliu,ejgan,tegmark}@mit.edu\n",
      "ABSTRACT\n",
      "We introduce Brain-Inspired Modular Training (BIMT), a method for making neural\n",
      "networks more modular and interpretable. Inspired by brains, BIMT embeds neu-\n",
      "rons in a geometric space and augments the loss function with a cost proportional\n",
      "to the length of each neuron connection. We demonstrate that BIMT discovers\n",
      "useful modular neural networks for many simple tasks, revealing compositional\n",
      "structures in symbolic formulas, interpretable decision boundaries and features\n",
      "for classification, and mathematical structure in algorithmic datasets. The ability\n",
      "to directly seemodules with the naked eye can complement current mechanistic\n",
      "interpretability strategies such as probes, interventions or staring at all weights.\n",
      "1 I NTRODUCTION\n",
      "Although deep neural networks have achieved great successes, mechanistically interpreting them\n",
      "remains quite challenging (Olah et al., 2020; Olsson et al., 2022; Michaud et al., 2023; Elhage et al.,\n",
      "2021; Wang et al., 2023). If a neural network can be decomposed into smaller modules (Olah et al.,\n",
      "2020), interpretability may become much easier.\n",
      "In contrast to artificial neural networks, brains are remarkably modular (Bear et al., 2020). We\n",
      "conjecture that this is because artificial neural networks (e.g., fully connected neural networks) have a\n",
      "symmetry that brains lack: both the loss function and the most popular regularizers are invariant under\n",
      "permutations of neurons in each layer. In contrast, the cost of connecting two biological neurons\n",
      "depends on how far apart they are, because an axon needs to traverse this distance, thereby using\n",
      "energy and brain volume and causing time delay.\n",
      "To facilitate the discovery of more modular and interpretable neural networks, we introduce Brain-energy and brain volume and causing time delay.\n",
      "To facilitate the discovery of more modular and interpretable neural networks, we introduce Brain-\n",
      "Inspired Modular Training (BIMT). Inspired by brains, we embed neurons in a geometric space\n",
      "where distances are defined, and augment the loss function with a cost proportional to the length\n",
      "of each neuron connection times the absolute value of the connection weight. This obviously\n",
      "encourages locality ,i.e., keeping neurons that need to communicate as close together as possible.\n",
      "Any Riemannian manifold can be used; we explore 2D and 3D Euclidean space for easy visualization\n",
      "(see Figure 1).\n",
      "We demonstrate the power of BIMT on a broad range of tasks, finding that it can reveal interesting\n",
      "and sometimes unexpected structures. On symbolic formula datasets, BIMT is able to discover\n",
      "structures such as independence, compositionality and features sharing, which are useful for scientific\n",
      "applications. For classifications tasks, we find that BIMT may produce interpretable decision\n",
      "boundaries and features. For algorithmic tasks, we find BIMT to produce tree-like connectivity\n",
      "graphs, not only supporting the group representation argument in Chughtai et al. (2023), but also\n",
      "revealing a (somewhat unexpected) mechanism where multiple modules vote. Although most of our\n",
      "experiments are conducted on fully connected networks for vector inputs, we also conduct experiments\n",
      "demonstrating that BIMT generalizes to other types of data (e.g., images) and architectures (e.g.,\n",
      "transformers).\n",
      "This paper is organized as follows: Section 2 introduces brain-inspired modular training (BIMT).\n",
      "Section 3 applies BIMT to various tasks, demonstrating its interpretability power. We describe related\n",
      "work in Section 4 and discuss our conclusions in Section 5.\n",
      "1Figure 1: Top: Brain-inspired modular training (BIMT) contains three ingredients: (1) embedding\n",
      "neurons into a geometric space (e.g., 2D Euclidean space); (2) training with regularization which1Figure 1: Top: Brain-inspired modular training (BIMT) contains three ingredients: (1) embedding\n",
      "neurons into a geometric space (e.g., 2D Euclidean space); (2) training with regularization which\n",
      "penalizes non-local weights more; (3) swapping neurons during training to further enhance locality.\n",
      "Bottom: Zoo of modular networks obtained via BIMT (see experiments for details).\n",
      "2 B RAIN -INSPIRED MODULAR TRAINING (BIMT)\n",
      "Human brains are modular and sparse, which is arguably the reason why they are so efficient. To\n",
      "make neural networks more efficient, it is desirable to make them modular and sparse, just like our\n",
      "brains. Sparsity is a well-studied topic in neural networks, and can be encouraged by including\n",
      "L1/L2penalty in training or by applying pruning to model weights (Han et al., 2015; Anwar et al.,\n",
      "2017). As for modularity, most of research explicitly introduce modules (Pfeiffer et al., 2023; Kirsch\n",
      "et al., 2018), but this requires prior knowledge about problem structures. Our motivation question is\n",
      "thus:\n",
      "Q: What training techniques can induce modularity in otherwise non-modular networks?\n",
      "In other words, our goal is to let modularity emerge from non-modular networks. In this section, we\n",
      "propose a method called Brain-Inspired Modular Training (BIMT), which explicitly steers neural\n",
      "networks to become more modular and sparse during training. BIMT consists of three key ingredients\n",
      "(see Figure 1): (1) embedding the network to a geometric space; (2) training to encourage locality\n",
      "and sparsity; (3) swapping neurons for better locality.\n",
      "Notation For simplicity we describe how to do BIMT with fully connected networks; generalization\n",
      "to other architectures is possible. We distinguish between weight layers andneuron layers . Assuming\n",
      "a fully connected network to have Lweight layers, whose ithweight layer (i= 1,···, L)has weights\n",
      "Wi∈Rni−1×niand biases bi∈Rni, where ni−1andniare the number of neurons incoming toa fully connected network to have Lweight layers, whose ithweight layer (i= 1,···, L)has weights\n",
      "Wi∈Rni−1×niand biases bi∈Rni, where ni−1andniare the number of neurons incoming to\n",
      "and outgoing from the ithweight layer. The ith(i= 0,···, L)neuron layer has nineurons. The\n",
      "input and output dimension of the whole network is n0andnL, respectively.\n",
      "Step 1: Embedding the network to a geometric space We now embed the whole network into a\n",
      "space where the jthneuron in the ithlayer is the (i, j)neuron located at rij. If this is 2D Euclidean\n",
      "space, neurons in the same neuron layer share the same y-coordinate and are uniformly spaced in\n",
      "x∈[0, A](A > 0). Different neuron layers are vertically separated by a distance y∗>0, so\n",
      "rij≡(xij, yij) = (Aj/n i, iy∗). (1)\n",
      "The weight that connects the (i−1, j)neuron and the (i, k)neuron has value wijk≡(Wi)jk, and\n",
      "the bias at the (i+ 1, k)neuron is bik≡(bi)kand its length is defined as\n",
      "dijk≡ |ri−1,j−rik|. (2)\n",
      "We will use L1-norm, giving dijk=A|xi−1,j−xik|+y∗, but other vector norms can also be used.\n",
      "For example, L2-norm gives dijk=\u0000\n",
      "A2|xi−1,j−xik|2+y2\n",
      "∗\u00011/2.\n",
      "2Figure 2: The connectivity graphs of neural networks when trained with different techniques for a\n",
      "regression problem (blue/red denote positive/negative weights). Our proposed BIMT = L1regulariza-\n",
      "tion (not novel) + local regularization (novel) + swap (novel). BIMT finds the simplest circuit (e)\n",
      "which clearly contains two parallel modules, with a small sacrifice in test loss compared to vanilla\n",
      "(a), but with lower loss than for mere L1regularization (b). Note that swapping aims to reduce the\n",
      "local connection cost, so all of (c)(d)(e) encourage locality.\n",
      "Step 2: imposing regularization that encourage locality We define the connection cost for weight\n",
      "and bias parameters of the whole network to be\n",
      "ℓw=LX\n",
      "i=1niX\n",
      "j=1ni+1X\n",
      "k=1dijk|wijk|, ℓb=LX\n",
      "i=1niX\n",
      "j=1y∗|bij|. (3)\n",
      "When training for a particular task, in addition to the prediction loss ℓpred, we include ℓwandℓbas\n",
      "regularizations:```\n",
      "    \n",
      "The JSON object:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ARXIV_MD_SUMMARIZATION_PROMPT_TEMPLATE = \"\"\"\n",
    "    You are an expert summarizer. You are given a portion of a paper and you have to summarize in {language} it in a concise way.\n",
    "    Concise means one paragraph each.\n",
    "    \n",
    "    Proceed this way:\n",
    "    a) First identify the abstract, sections and subsections in the chunk of the text provided delimited below by triple =. Ignore reference and acknowledgements sections.\n",
    "    b) Per each section, including also sections and subsections in the appendices and/or supplementary material:\n",
    "        b.1) Create a markdown document for the section following these rules:\n",
    "            b.1.1) Heading level 1 should be the title of the paper.\n",
    "            b.1.2) Heading level 2 should be the title of abstract or each section.\n",
    "            b.1.3) Heading level 3 should be the summary of each sub-section.\n",
    "            b.1.4) The summary of each section or subsection should be in regular text.\n",
    "            b.1.5) The summary of each section should be followed by a horizontal rule.\n",
    "        b.2) The markdown document for the secition, will include the title of the abstract, section or subsection, and in a paragraph then the summary of it. Do not include in \n",
    "        the summary the legend of the figures.\n",
    "    c) Aggregate, preserving the order, the markdown documents of each section/subsection into a single markdown document.\n",
    "    \n",
    "    You will return a JSON object with to properties. \n",
    "    The first property will be named 'partial_summarization' will contain the aggregated markdown document string. \n",
    "    The second property will be named 'remaining_text' and will contain the title and text of the last section if the title\n",
    "    or the text of that section/subsection was cut in the middle. Otherwise, 'remaining_text' should return 'N/A'.\n",
    "\n",
    "    ==={text}===\n",
    "    \n",
    "    The JSON object:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "ARXIV_MD_SUMMARIZATION_PROMPT_TEMPLATE = \"\"\"\n",
    "Please identify and extract all distinct sections from the provided technical paper, including the title, abstract, introduction, \n",
    "methodology, results, discussion, conclusion, and any other relevant parts. Return the extracted sections as a JSON object, with each\n",
    "section as a key-value pair, where the key is the section name and the value is the corresponding text. The text is as shown below \n",
    "surrounded by triple batticks.\n",
    "   \n",
    "```{text}```\n",
    "    \n",
    "The JSON object:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "ARXIV_MD_SUMMARIZATION_PROMPT = PromptTemplate(\n",
    "    template=ARXIV_MD_SUMMARIZATION_PROMPT_TEMPLATE, input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "current_tokens = 0\n",
    "current_context = ''\n",
    "for doc in docs:\n",
    "    if current_tokens < 2000:\n",
    "        chunk = doc.page_content\n",
    "        chunk_tokens = llm.get_num_tokens(chunk)\n",
    "        current_context += chunk\n",
    "        current_tokens += chunk_tokens\n",
    "    else:\n",
    "        print(f\"Calling ChatGPT3 with {current_tokens} tokens\")\n",
    "        # args = {\"input_documents\": current_context, \"language\": \"english\"}\n",
    "        prompt=ARXIV_MD_SUMMARIZATION_PROMPT\n",
    "        \n",
    "        formatted_prompt = prompt.format(text=current_context)\n",
    "        \n",
    "        from utils import get_gai_completion\n",
    "        import json\n",
    "        \n",
    "        print(formatted_prompt)\n",
    "        # completion = get_gai_completion(formatted_prompt)\n",
    "        # print(completion)\n",
    "        # outputs = json.loads(completion)\n",
    "        # print(outputs)\n",
    "        \n",
    "        # print(outputs['partial_summarization'])\n",
    "        # print(outputs['remaining_text'])\n",
    "        \n",
    "        # # hm = HumanMessage(content=formatted_prompt)\n",
    "        # # chunk_summary = llm3([hm])\n",
    "\n",
    "        # print(\"Summary \" * 10)\n",
    "        # print(chunk_summary)\n",
    "        # print(chunk_summary.content)\n",
    "        current_tokens = 0\n",
    "        current_context = ''\n",
    "        break\n",
    "        \n",
    "        \n",
    "    # print(llm.get_num_tokens(doc.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_clusters):\n",
    "    \n",
    "    # Get the list of distances from that particular cluster center\n",
    "    distances = np.linalg.norm(vectors - kmeans.cluster_centers_[1], axis=1)\n",
    "    \n",
    "    closest_indexes = np.argsort(distances)[:10]\n",
    "    closest_indexes.sort()\n",
    "    print(closest_indexes)\n",
    "    # selected_indices = np.take(vectors, closest_indexes, axis=0)\n",
    "    # print(selected_indices)\n",
    "    selected_docs = [docs[doc].page_content for doc in closest_indexes]\n",
    "    section = \"\\n\".join(selected_docs)\n",
    "    print(section)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
